{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af22c362",
   "metadata": {},
   "source": [
    "# How do we work with several texts at once?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d7019",
   "metadata": {},
   "source": [
    "Regardless of whether our data consists of literary texts, tweets, emails, survey responses, or numbers, data frames (tables - think of spreadsheets) are the most effective way to handle them.\n",
    "\n",
    "Often (but not always), we distinguish between data and metadata. Metadata is data about data. In our case, the texts would be our data, and information about the texts, such as author, title, and year, would be our metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c7331",
   "metadata": {},
   "source": [
    "The most important package for working with data frames is 'Pandas'. However, sometimes we need to import more than one library because some libraries build on the functionality of others. For the tasks below, in addition to Pandas, we also need to use the libraries called 'os' and 'numpy'.\n",
    "\n",
    "You can read more about Pandas and Numpy here:\n",
    "\n",
    "Link to Pandas documentation: https://pandas.pydata.org/pandas-docs/stable/\n",
    "\n",
    "Link to Numpy documentation https://numpy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48befae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works on PC\n",
    "\n",
    "texts = []\n",
    "\n",
    "for speech in os.scandir(r\"C:\\Users\\au576018\\OneDrive - Aarhus Universitet\\Documents\\Kurser\\kvantitativ diskursanalyse\\quantitative_discourse_analysis\\data\\politicians\\english\\trump\"):\n",
    "    x = open(speech, encoding = \"utf8\")\n",
    "    y = x.read()\n",
    "    z = y.replace(\"\\n\", \" \")\n",
    "    texts.append(z)\n",
    "    x.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c7ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works on mac\n",
    "\n",
    "# texts = [] \n",
    "\n",
    "path = os.path.join(\"text-files-path\") # bruges for at undg√• mac/pc-problemerne med absolutte stinavne\n",
    "\n",
    "for fil in os.scandir(path): # for-loop\n",
    "    with open (fil, encoding = \"utf8\") as f: # context manager\n",
    "        texts.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec6d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d8d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b019bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e45ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4200627",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fca842",
   "metadata": {},
   "source": [
    "# Example on Pandas\n",
    "\n",
    "Here's a small example on how to create a dataframe with pandas\n",
    "\n",
    "I want to combine lists of numbers and lists of texts in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c63c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # creating a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "written_numbers = [\"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\", \"Ten\"] # creating a list of text elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0593fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "written_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.DataFrame({\"Numbers\": numbers, \"Written numbers\": written_numbers}) # making a dataframe called \"test_dataframe\" from the two lists we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b558042",
   "metadata": {},
   "source": [
    "I know have some additional information to add in my dataframe. I can add this information to my existing dataframe by simply specify the names of the new column and the data I want in that specific column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are my lists of new information I want to add to my existing dataframe\n",
    "\n",
    "colors = [\"Red\", \"Blue\", \"Yellow\",\"Green\", \"Purple\", \"White\", \"Grey\", \"Orange\", \"Black\", \"Pink\"]\n",
    "mood = [\"Happy\", \"Happy\", \"Sad\", \"Happy\" ,\"Sad\", \"Sad\", \"Sad\", \"Happy\", \"Happy\", \"Happy\"]\n",
    "amount = [\"25\", \"27\", \"3\",\"19\", \"41\", \"5\", \"6\", \"33\", \"43\", \"7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a56e0a",
   "metadata": {},
   "source": [
    "I know add the new columns one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c3ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe[\"Colors\"] = colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590051f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b972787",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe[\"Mood\"] = mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe[\"Amount\"] = amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f14133",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f7948",
   "metadata": {},
   "source": [
    "We can make several calculations directly on our dataframe. Basically you can do the same operations in a dataframe as you can ouotside a dataframe. You just have to be aware of the type of data you are working with.\n",
    "\n",
    "Here's an example on extracting the first letter in every word in the column \"Mood\", and add these letters in a new column.\n",
    "(This way of doing the operation is called list comprehension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1fe7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe[\"First letter of mood\"] = [letter[0] for letter in test_dataframe[\"Mood\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ed6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad547bfc",
   "metadata": {},
   "source": [
    "The options are many, and you can use google or chatgpt to your advantage, if you have a specific task for your program in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5eb520",
   "metadata": {},
   "source": [
    "The pandas package has several in-built functionalities to inspect your data (you should ALWAYS inspect your data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b287aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe.head() # shows the top 5 rows of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd48942",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe.tail() # shows the bottom 5 rows of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe[2:6] # shows the dataframe from the row index 2 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd195da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe[\"Colors\"] # shows the column \"Colors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe[[\"Colors\", \"Amount\"]] # shows the columns \"Colors\" and \"Amount\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c223d",
   "metadata": {},
   "source": [
    "If can also slice your dataframe by the names of your rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8402caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe.loc[0:4, \"Colors\": \"Amount\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b77754",
   "metadata": {},
   "source": [
    "### Small exercise: Try the following lines for yourself. What do you get?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7112d3ce",
   "metadata": {},
   "source": [
    "```\n",
    "test_dataframe.loc[3:7, \"Colors\": \"Amount\"]\n",
    "test_dataframe.loc[: \"Mood\"]\n",
    "test_dataframe.loc[4, :]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd3978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c626fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db50c5a0",
   "metadata": {},
   "source": [
    "If we define a function we can all it on a whole column at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe[\"Length of color\"] = test_dataframe.Colors.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb3d8a",
   "metadata": {},
   "source": [
    "If you want to reach single cells by index or a given value, you can use the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d18a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe[\"Amount\"][1] # goes to the column \"Amount\" and the row at index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1996724",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe[test_dataframe[\"Mood\"] == \"Happy\"] # goes to the column \"Mood\" and make a subset containing every row with the value \"Happy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad636f4",
   "metadata": {},
   "source": [
    "When you are done with your dataframe, you can save it as a csv-file by the follwing command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee266f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe.to_csv('test_dataset.csv', index=False) # change the name of the file by substituting \"test_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1d6b2",
   "metadata": {},
   "source": [
    "# Lets apply our analysis from earlier in the dataframa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0dfad0",
   "metadata": {},
   "source": [
    "First we want to arrange the speeches in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302cf834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = DataFrame({\"Speeches\": texts})\n",
    "df_speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21334feb",
   "metadata": {},
   "source": [
    "Now we want to clean up the mess within the texts. We can make a function and do it in all texts at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c4911",
   "metadata": {},
   "source": [
    "we used this with code on one text, and now want to make a function to do it an all the texts.\n",
    "\n",
    "``` \n",
    "speech_clean = speech.replace(\"\\n\", \" \")\n",
    "speech_clean \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11414e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(txt): # we define a function called \"clean\" which takes a text argument\n",
    "    return txt.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb32d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches[\"Clean_texts\"] = df_speeches.Speeches.apply(clean) # we make a column \"Clean_texts\" by applying the clean-function on the column \"Speeches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00985b92",
   "metadata": {},
   "source": [
    "# Spacy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a386be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy # import spacy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\") # load your language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff96ee74",
   "metadata": {},
   "source": [
    "We now want to make the texts in the dataframe an nlp-object, in order to make our analysis. We can do this at once on a whole column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches[\"nlp_texts\"] = df_speeches.Clean_texts.apply(nlp) # applying nlp-function on the \"Clean\" column, and add it as a new column \"nlp_texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17539a",
   "metadata": {},
   "source": [
    "We can inspect our data by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf48f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches[\"nlp_texts\"][2] # gives you the nlp_columns at row index 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_speeches[\"nlp_texts\"][2]) # gives you the type of the element in the nlp_column at row index 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154723f5",
   "metadata": {},
   "source": [
    "We can now use the spacy functionality on the nlp_texts column, since they are spacy-objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_speeches[\"nlp_texts\"][2].sents)) # gives us every sentence in the text seperated by a comma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c5d141",
   "metadata": {},
   "source": [
    "We can still print them one by one in order to make it more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7693174",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in df_speeches[\"nlp_texts\"][2].sents: # for every sentence in text at second index in column \"nlp_texts\"\n",
    "    print(sentence) # print the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa7d67",
   "metadata": {},
   "source": [
    "We can make a new column in the dataframe containing every senteces of the text by turning the code above into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d88a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences(nlp_object): # defines a function \"sentences\" that takes an nlp-object as an input\n",
    "    sentences = [] # place holder for sentences\n",
    "    for sentence in nlp_object.sents: # for every sentence\n",
    "        sentences.append(sentence) # appende sentence to the list \"sentences\". if you do not want to analyze sentences as nlp-objects, you can add \"str()\"\n",
    "    return sentences # returns the collection of sentences in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c123a4f5",
   "metadata": {},
   "source": [
    "We make the new column \"Sentences\" by calling our function at the column \"nlp_texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f11a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches[\"Sentences\"] = df_speeches.nlp_texts.apply(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5ed32",
   "metadata": {},
   "source": [
    "We now want to find the most used nouns in every text. By using the code from earlier, this can be done easily by calling functions on the columns in the dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a3cae",
   "metadata": {},
   "source": [
    "first we recall our counting-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def sorted_count(a):\n",
    "    b = Counter(a)\n",
    "    c = sorted(b.items(), key=lambda item: item[1], reverse = True)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768ee53",
   "metadata": {},
   "source": [
    "and the function finding the most frequent nouns in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8665a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequent_nouns(nlp_object): # we find the lemmas\n",
    "    nouns = [token.lemma_ for token in nlp_object if token.pos_ == \"NOUN\"]\n",
    "    most_frequent = sorted_count(nouns)[:3]\n",
    "    return most_frequent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13136710",
   "metadata": {},
   "source": [
    "We call the \"frequent_nouns\"-function on the column \"nlp_texts\" and add the result in a new column \"Frequent_nouns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa37e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches[\"Frequent_nouns\"] = df_speeches.nlp_texts.apply(frequent_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4b51b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80023f4",
   "metadata": {},
   "source": [
    "# Exersice. Do the same analysis on the 10 speeches by Obama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de24cf",
   "metadata": {},
   "source": [
    "It might help to follow this order\n",
    "\n",
    "- load the data\n",
    "- make a dataframe with the new data\n",
    "- clean your data from \"\\n\" and add as a new column\n",
    "- make each text an nlp object and add as a new column\n",
    "- make a column with the sentences from the text\n",
    "- make a column with the most frequent nouns\n",
    "\n",
    "\n",
    "(SOLUTION is further down. But try your best and ask for help before looking at the solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4164f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works on PC\n",
    "\n",
    "texts_obama = []\n",
    "\n",
    "for speech in os.scandir(r\"C:\\Users\\au576018\\OneDrive - Aarhus Universitet\\Documents\\Kurser\\kvantitativ diskursanalyse\\quantitative_discourse_analysis\\data\\politicians\\english\\obama\"):\n",
    "    x = open(speech, encoding = \"utf8\")\n",
    "    texts_obama.append(x.read())\n",
    "    x.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe from your speeches\n",
    "\n",
    "df_speeches_obama = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a02a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21967c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c91fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96578512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53170b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac47da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f7fd62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98b8b771",
   "metadata": {},
   "source": [
    "## Related adjectives (Extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94ab4d",
   "metadata": {},
   "source": [
    "The word \"people\" is very frequent throughout the dataset. Find the noun chunks to the keyword \"people\" (see Notebook 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978cf0e5",
   "metadata": {},
   "source": [
    "Help\n",
    "- make a function that find the sentences where the word \"people\" is included\n",
    "- apply this function on every text in the dataframe. make it a new column\n",
    "- find the noun chunks with the root \"people\" and apply as a new column in your dataframe\n",
    "- BONUS: extract only the adjective that describes the root \"people\", and add as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430e196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3cb104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0073e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf3c2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bdd54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24c2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ed88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4fac9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d3b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07827e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38c44f72",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bfae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works on PC\n",
    "\n",
    "texts_obama = []\n",
    "\n",
    "for speech in os.scandir(r\"C:\\Users\\au576018\\OneDrive - Aarhus Universitet\\Documents\\Kurser\\kvantitativ diskursanalyse\\quantitative_discourse_analysis\\data\\politicians\\english\\obama\"):\n",
    "    x = open(speech, encoding = \"utf8\")\n",
    "    texts_obama.append(x.read())\n",
    "    x.close()\n",
    "\n",
    "# make a dataframe from your speeches\n",
    "\n",
    "df_speeches_obama = DataFrame({\"Speeches\": texts_obama})\n",
    "df_speeches_obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d0d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_obama[\"Clean\"] = df_speeches_obama.Speeches.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_obama[\"nlp_texts\"] = df_speeches_obama.Clean.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_obama[\"Sentences\"] = df_speeches_obama.nlp_texts.apply(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5036e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_obama[\"Frequent_nouns\"] = df_speeches_obama.nlp_texts.apply(frequent_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_obama"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
